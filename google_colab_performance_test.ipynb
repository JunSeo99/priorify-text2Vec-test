{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Korean Text Categorization Performance Test on Google Colab\n",
        "## MPS vs CUDA vs CPU 성능 비교\n",
        "\n",
        "이 노트북은 한국어 텍스트 분류 성능을 다양한 하드웨어에서 테스트합니다.\n",
        "\n",
        "**주요 기능:**\n",
        "- V1 (단순 카테고리 이름 비교) vs V2 (NER + 키워드 평균 임베딩) 비교\n",
        "- CPU, CUDA, MPS 성능 벤치마크\n",
        "- 실제 한국어 일정 데이터를 이용한 테스트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요한 패키지 설치\n",
        "!pip install sentence-transformers transformers torch scikit-learn pandas numpy tqdm matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from typing import List, Dict, Tuple\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 하드웨어 정보 확인\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
        "\n",
        "# MPS 지원 확인 (Apple Silicon)\n",
        "print(f\"MPS available: {torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False}\")\n",
        "\n",
        "# 사용할 디바이스 결정\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = 'mps'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 테스트 데이터 (실제 프로젝트의 일부 데이터)\n",
        "test_data = [\n",
        "    (\"깃헙 회의\", [\"학업\", \"친목\", \"업무\"]),\n",
        "    (\"자료구조 과제 제출\", [\"학업\"]),\n",
        "    (\"알고리즘 스터디 모임\", [\"학업\", \"친목\"]),\n",
        "    (\"백준 풀기\", [\"학업\", \"취미\"]),\n",
        "    (\"운영체제 중간고사 공부 계획 세우기\", [\"학업\", \"시험\"]),\n",
        "    (\"졸업 프로젝트 아이디어 구상 및 주제 선정\", [\"학업\"]),\n",
        "    (\"국가근로장학금 신청 서류 제출\", [\"경제\", \"재무\", \"학업\"]),\n",
        "    (\"노트북 쿨링팬 청소 및 서멀구리스 재도포\", [\"취미\", \"가사\"]),\n",
        "    (\"월세 및 통신비 이체\", [\"정기 지출\", \"경제\"]),\n",
        "    (\"헌혈의 집 방문하여 헌혈하기\", [\"봉사\", \"건강\"]),\n",
        "    (\"라식 수술 상담 예약\", [\"건강\", \"예약\", \"미용\"]),\n",
        "    (\"친구들과 보드게임 카페 방문\", [\"친목\", \"취미\"]),\n",
        "    (\"중고 전공서적 판매글 올리기\", [\"구매\", \"경제\"]),\n",
        "    (\"시댁 방문 및 김장 도와드리기\", [\"가족\", \"봉사\"]),\n",
        "    (\"반려견 산책 및 동물병원 방문\", [\"반려 동물\", \"건강\"]),\n",
        "    (\"과제 채점하기\", [\"업무\", \"학업\", \"시험\"]),\n",
        "    (\"발표대본 만들기\", [\"업무\", \"학업\", \"시험\"]),\n",
        "    (\"브랜드 협찬 제품 리뷰 영상 기획\", [\"업무\", \"구매\"]),\n",
        "    (\"애인과 커플 요금제 상담\", [\"연애\", \"통화\", \"경제\"]),\n",
        "    (\"부모님 스마트폰 백업 도와드리기\", [\"가족\", \"봉사\"])\n",
        "]\n",
        "\n",
        "print(f\"Test data loaded: {len(test_data)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 카테고리 정의 (개선된 키워드 버전) - 주요 카테고리만\n",
        "CATEGORIES = {\n",
        "    \"학업\": [\n",
        "        \"과제 작성하고 제출하기\", \"시험 준비하고 공부하기\", \"수업 듣고 참여하기\", \n",
        "        \"논문 작성하고 연구하기\", \"프로젝트 기획하고 진행하기\", \"스터디 참여하고 토론하기\",\n",
        "        \"학점 관리하고 성적 확인하기\", \"졸업 요건 확인하고 준비하기\", \"전공 심화 학습하기\",\n",
        "        \"학술 활동 참여하기\", \"도서관에서 자료 조사하기\", \"온라인 강의 수강하기\"\n",
        "    ],\n",
        "    \"업무\": [\n",
        "        \"회의 참석하고 업무 논의하기\", \"업무 계획 수립하고 실행하기\", \"프레젠테이션 준비하고 발표하기\",\n",
        "        \"클라이언트와 미팅하고 상담하기\", \"업무 보고서 작성하고 제출하기\", \"프로젝트 관리하고 진행하기\",\n",
        "        \"동료와 협업하고 소통하기\", \"업무 스킬 향상하고 교육받기\", \"성과 평가받고 피드백하기\",\n",
        "        \"업무 환경 개선하고 최적화하기\", \"고객 서비스 제공하고 응대하기\", \"팀 업무 조율하고 관리하기\"\n",
        "    ],\n",
        "    \"건강\": [\n",
        "        \"운동하고 체력 관리하기\", \"병원 방문하고 검진받기\", \"약 복용하고 치료받기\",\n",
        "        \"건강한 식단 관리하고 섭취하기\", \"정기 건강검진 받기\", \"스트레스 관리하고 휴식하기\",\n",
        "        \"충분한 수면 취하고 컨디션 관리하기\", \"금연 금주하고 건강 습관 유지하기\",\n",
        "        \"정신 건강 관리하고 상담받기\", \"예방접종 받고 감염 예방하기\"\n",
        "    ],\n",
        "    \"경제\": [\n",
        "        \"가계부 작성하고 지출 관리하기\", \"적금 저축하고 재정 계획하기\", \"투자 상품 알아보고 운용하기\",\n",
        "        \"용돈 관리하고 예산 세우기\", \"할인 혜택 찾고 절약하기\", \"부채 관리하고 상환하기\",\n",
        "        \"가격 비교하고 합리적 소비하기\", \"수입 늘리고 부업 알아보기\", \"보험료 납부하고 보장받기\"\n",
        "    ],\n",
        "    \"친목\": [\n",
        "        \"친구들과 만나서 수다떨기\", \"동료들과 회식하고 친해지기\", \"모임 참석하고 네트워킹하기\",\n",
        "        \"지인들과 취미 활동 함께하기\", \"새로운 사람들과 인맥 쌓기\", \"가족 모임 참석하고 소통하기\",\n",
        "        \"커뮤니티 활동 참여하고 교류하기\", \"파티 참석하고 즐기기\"\n",
        "    ],\n",
        "    \"취미\": [\n",
        "        \"독서하고 책 감상하기\", \"영화 보고 드라마 시청하기\", \"음악 듣고 악기 연주하기\",\n",
        "        \"게임하고 오락 즐기기\", \"요리하고 베이킹하기\", \"운동하고 스포츠 활동하기\",\n",
        "        \"여행 계획하고 떠나기\", \"사진 촬영하고 편집하기\", \"공예 만들고 DIY하기\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(f\"Categories defined: {len(CATEGORIES)} categories\")\n",
        "for cat, keywords in CATEGORIES.items():\n",
        "    print(f\"{cat}: {len(keywords)} keywords\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PerformanceTester:\n",
        "    def __init__(self, device='cpu'):\n",
        "        self.device = device\n",
        "        print(f\"Initializing models on {device}...\")\n",
        "        \n",
        "        # SentenceTransformer 모델 로드\n",
        "        self.sentence_model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
        "        if device != 'cpu':\n",
        "            self.sentence_model.to(device)\n",
        "        \n",
        "        # NER 모델 로드\n",
        "        self.ner_pipeline = pipeline(\n",
        "            \"ner\",\n",
        "            model=\"Leo97/KoELECTRA-small-v3-modu-ner\",\n",
        "            tokenizer=\"Leo97/KoELECTRA-small-v3-modu-ner\",\n",
        "            aggregation_strategy=\"simple\",\n",
        "            device=0 if device == 'cuda' else -1\n",
        "        )\n",
        "        \n",
        "        # 카테고리 임베딩 미리 계산\n",
        "        self._precompute_category_embeddings()\n",
        "        \n",
        "    def _precompute_category_embeddings(self):\n",
        "        \"\"\"카테고리 임베딩을 미리 계산\"\"\"\n",
        "        print(\"Precomputing category embeddings...\")\n",
        "        \n",
        "        # V1: 단순 카테고리 이름\n",
        "        self.category_embeddings_v1 = {}\n",
        "        category_names = list(CATEGORIES.keys())\n",
        "        embeddings = self.sentence_model.encode(category_names)\n",
        "        for name, embedding in zip(category_names, embeddings):\n",
        "            self.category_embeddings_v1[name] = embedding\n",
        "            \n",
        "        # V2: 키워드 평균 임베딩\n",
        "        self.category_embeddings_v2 = {}\n",
        "        for category, keywords in CATEGORIES.items():\n",
        "            keyword_embeddings = self.sentence_model.encode(keywords)\n",
        "            avg_embedding = np.mean(keyword_embeddings, axis=0)\n",
        "            self.category_embeddings_v2[category] = avg_embedding\n",
        "            \n",
        "    def preprocess_with_ner(self, text: str) -> str:\n",
        "        \"\"\"NER로 텍스트 전처리\"\"\"\n",
        "        try:\n",
        "            entities = self.ner_pipeline(text)\n",
        "            processed_text = text\n",
        "            \n",
        "            # 엔티티를 플레이스홀더로 변경 (긴 것부터 처리)\n",
        "            entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
        "            \n",
        "            for entity in entities:\n",
        "                if entity['entity_group'] == 'PER':\n",
        "                    placeholder = '<PERSON>'\n",
        "                elif entity['entity_group'] == 'LOC':\n",
        "                    placeholder = '<LOCATION>'\n",
        "                elif entity['entity_group'] == 'ORG':\n",
        "                    placeholder = '<ORG>'\n",
        "                else:\n",
        "                    continue\n",
        "                    \n",
        "                processed_text = (\n",
        "                    processed_text[:entity['start']] + \n",
        "                    placeholder + \n",
        "                    processed_text[entity['end']:]\n",
        "                )\n",
        "                \n",
        "            return processed_text\n",
        "        except:\n",
        "            return text\n",
        "            \n",
        "    def predict_v1(self, text: str, threshold: float = 0.5) -> List[str]:\n",
        "        \"\"\"V1: 단순 카테고리 이름 비교\"\"\"\n",
        "        text_embedding = self.sentence_model.encode([text])[0]\n",
        "        \n",
        "        predictions = []\n",
        "        for category, category_embedding in self.category_embeddings_v1.items():\n",
        "            similarity = cosine_similarity([text_embedding], [category_embedding])[0][0]\n",
        "            if similarity >= threshold:\n",
        "                predictions.append((category, similarity))\n",
        "                \n",
        "        # 유사도 순으로 정렬\n",
        "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [pred[0] for pred in predictions]\n",
        "        \n",
        "    def predict_v2(self, text: str, threshold: float = 0.5) -> List[str]:\n",
        "        \"\"\"V2: NER + 키워드 평균 임베딩\"\"\"\n",
        "        # NER 전처리\n",
        "        processed_text = self.preprocess_with_ner(text)\n",
        "        text_embedding = self.sentence_model.encode([processed_text])[0]\n",
        "        \n",
        "        predictions = []\n",
        "        for category, category_embedding in self.category_embeddings_v2.items():\n",
        "            similarity = cosine_similarity([text_embedding], [category_embedding])[0][0]\n",
        "            if similarity >= threshold:\n",
        "                predictions.append((category, similarity))\n",
        "                \n",
        "        # 유사도 순으로 정렬\n",
        "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [pred[0] for pred in predictions]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PerformanceTester 클래스에 벤치마크 메서드 추가\n",
        "def benchmark(self, test_data: List[Tuple], num_runs: int = 3):\n",
        "    \"\"\"성능 벤치마크\"\"\"\n",
        "    results = {\n",
        "        'v1_times': [],\n",
        "        'v2_times': [],\n",
        "        'v1_accuracy': [],\n",
        "        'v2_accuracy': []\n",
        "    }\n",
        "    \n",
        "    for run in range(num_runs):\n",
        "        print(f\"\\\\nRun {run + 1}/{num_runs}\")\n",
        "        \n",
        "        # V1 테스트\n",
        "        start_time = time.time()\n",
        "        v1_correct = 0\n",
        "        \n",
        "        for text, true_categories in tqdm(test_data, desc=\"V1 Testing\"):\n",
        "            predictions = self.predict_v1(text)\n",
        "            if any(pred in true_categories for pred in predictions):\n",
        "                v1_correct += 1\n",
        "                \n",
        "        v1_time = time.time() - start_time\n",
        "        v1_accuracy = v1_correct / len(test_data)\n",
        "        \n",
        "        results['v1_times'].append(v1_time)\n",
        "        results['v1_accuracy'].append(v1_accuracy)\n",
        "        \n",
        "        # V2 테스트\n",
        "        start_time = time.time()\n",
        "        v2_correct = 0\n",
        "        \n",
        "        for text, true_categories in tqdm(test_data, desc=\"V2 Testing\"):\n",
        "            predictions = self.predict_v2(text)\n",
        "            if any(pred in true_categories for pred in predictions):\n",
        "                v2_correct += 1\n",
        "                \n",
        "        v2_time = time.time() - start_time\n",
        "        v2_accuracy = v2_correct / len(test_data)\n",
        "        \n",
        "        results['v2_times'].append(v2_time)\n",
        "        results['v2_accuracy'].append(v2_accuracy)\n",
        "        \n",
        "        print(f\"V1 - Time: {v1_time:.2f}s, Accuracy: {v1_accuracy:.3f}\")\n",
        "        print(f\"V2 - Time: {v2_time:.2f}s, Accuracy: {v2_accuracy:.3f}\")\n",
        "        \n",
        "    return results\n",
        "\n",
        "# 메서드를 클래스에 바인딩\n",
        "PerformanceTester.benchmark = benchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 각 디바이스별 성능 테스트\n",
        "devices_to_test = ['cpu']\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    devices_to_test.append('cuda')\n",
        "    \n",
        "if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    devices_to_test.append('mps')\n",
        "\n",
        "print(f\"Testing on devices: {devices_to_test}\")\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "for device in devices_to_test:\n",
        "    print(f\"\\\\n{'='*50}\")\n",
        "    print(f\"Testing on {device.upper()}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    try:\n",
        "        tester = PerformanceTester(device=device)\n",
        "        results = tester.benchmark(test_data, num_runs=2)  # Colab에서는 2번만\n",
        "        all_results[device] = results\n",
        "        \n",
        "        # 평균 결과 출력\n",
        "        print(f\"\\\\n{device.upper()} Average Results:\")\n",
        "        print(f\"V1 - Avg Time: {np.mean(results['v1_times']):.2f}s ± {np.std(results['v1_times']):.2f}\")\n",
        "        print(f\"V1 - Avg Accuracy: {np.mean(results['v1_accuracy']):.3f} ± {np.std(results['v1_accuracy']):.3f}\")\n",
        "        print(f\"V2 - Avg Time: {np.mean(results['v2_times']):.2f}s ± {np.std(results['v2_times']):.2f}\")\n",
        "        print(f\"V2 - Avg Accuracy: {np.mean(results['v2_accuracy']):.3f} ± {np.std(results['v2_accuracy']):.3f}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error testing on {device}: {e}\")\n",
        "        continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 결과 비교 및 시각화\n",
        "if len(all_results) > 1:\n",
        "    # 성능 비교 차트\n",
        "    devices = list(all_results.keys())\n",
        "    v1_times = [np.mean(all_results[device]['v1_times']) for device in devices]\n",
        "    v2_times = [np.mean(all_results[device]['v2_times']) for device in devices]\n",
        "    v1_accuracies = [np.mean(all_results[device]['v1_accuracy']) for device in devices]\n",
        "    v2_accuracies = [np.mean(all_results[device]['v2_accuracy']) for device in devices]\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    \n",
        "    # 시간 비교\n",
        "    x = np.arange(len(devices))\n",
        "    width = 0.35\n",
        "    \n",
        "    ax1.bar(x - width/2, v1_times, width, label='V1 (Simple)', alpha=0.8, color='skyblue')\n",
        "    ax1.bar(x + width/2, v2_times, width, label='V2 (NER+Keywords)', alpha=0.8, color='lightcoral')\n",
        "    ax1.set_xlabel('Device')\n",
        "    ax1.set_ylabel('Time (seconds)')\n",
        "    ax1.set_title('Inference Time Comparison')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels([d.upper() for d in devices])\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 정확도 비교\n",
        "    ax2.bar(x - width/2, v1_accuracies, width, label='V1 (Simple)', alpha=0.8, color='skyblue')\n",
        "    ax2.bar(x + width/2, v2_accuracies, width, label='V2 (NER+Keywords)', alpha=0.8, color='lightcoral')\n",
        "    ax2.set_xlabel('Device')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.set_title('Accuracy Comparison')\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels([d.upper() for d in devices])\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.set_ylim(0, 1)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 성능 향상률 계산\n",
        "    if 'cpu' in all_results:\n",
        "        cpu_v1_time = np.mean(all_results['cpu']['v1_times'])\n",
        "        cpu_v2_time = np.mean(all_results['cpu']['v2_times'])\n",
        "        \n",
        "        print(\"\\\\n\" + \"=\"*50)\n",
        "        print(\"Performance Improvement vs CPU\")\n",
        "        print(\"=\"*50)\n",
        "        \n",
        "        for device in devices:\n",
        "            if device != 'cpu':\n",
        "                device_v1_time = np.mean(all_results[device]['v1_times'])\n",
        "                device_v2_time = np.mean(all_results[device]['v2_times'])\n",
        "                \n",
        "                v1_speedup = cpu_v1_time / device_v1_time\n",
        "                v2_speedup = cpu_v2_time / device_v2_time\n",
        "                \n",
        "                print(f\"{device.upper()} vs CPU:\")\n",
        "                print(f\"  V1 Speedup: {v1_speedup:.2f}x\")\n",
        "                print(f\"  V2 Speedup: {v2_speedup:.2f}x\")\n",
        "                print()\n",
        "else:\n",
        "    print(\"Only one device tested, skipping comparison charts.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 샘플 예측 결과 확인\n",
        "if all_results:\n",
        "    # 가장 좋은 성능의 디바이스 사용\n",
        "    best_device = list(all_results.keys())[0]\n",
        "    if 'cuda' in all_results:\n",
        "        best_device = 'cuda'\n",
        "    elif 'mps' in all_results:\n",
        "        best_device = 'mps'\n",
        "        \n",
        "    tester = PerformanceTester(device=best_device)\n",
        "    \n",
        "    print(f\"\\\\nSample predictions using {best_device.upper()}:\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for i, (text, true_categories) in enumerate(test_data[:5]):\n",
        "        v1_pred = tester.predict_v1(text)\n",
        "        v2_pred = tester.predict_v2(text)\n",
        "        \n",
        "        print(f\"\\\\nSample {i+1}: {text}\")\n",
        "        print(f\"True categories: {true_categories}\")\n",
        "        print(f\"V1 predictions: {v1_pred}\")\n",
        "        print(f\"V2 predictions: {v2_pred}\")\n",
        "        \n",
        "        # 정확도 체크\n",
        "        v1_correct = any(pred in true_categories for pred in v1_pred)\n",
        "        v2_correct = any(pred in true_categories for pred in v2_pred)\n",
        "        \n",
        "        print(f\"V1 correct: {'✓' if v1_correct else '✗'}, V2 correct: {'✓' if v2_correct else '✗'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 결론 및 분석\n",
        "\n",
        "### MPS vs CUDA vs CPU 성능 분석:\n",
        "\n",
        "#### **왜 MPS가 기대만큼 빠르지 않을까?**\n",
        "\n",
        "1. **작은 배치 사이즈**: \n",
        "   - 텍스트 임베딩은 보통 한 번에 하나씩 처리\n",
        "   - GPU는 큰 배치에서 진가를 발휘하는데, 작은 배치에서는 오버헤드가 큼\n",
        "\n",
        "2. **메모리 전송 오버헤드**:\n",
        "   - CPU → GPU 데이터 전송 시간\n",
        "   - GPU → CPU 결과 전송 시간\n",
        "   - 실제 연산 시간보다 전송 시간이 더 클 수 있음\n",
        "\n",
        "3. **모델 크기**:\n",
        "   - SentenceTransformer는 상대적으로 작은 모델\n",
        "   - GPU의 병렬 처리 능력을 충분히 활용하지 못함\n",
        "\n",
        "4. **최적화 부족**:\n",
        "   - 모델이 GPU 최적화가 덜 되어 있을 수 있음\n",
        "   - 메모리 할당 패턴이 GPU에 최적화되지 않았을 수 있음\n",
        "\n",
        "#### **언제 GPU가 유리할까?**\n",
        "\n",
        "- **배치 크기가 큰 경우** (100개 이상의 텍스트를 한 번에 처리)\n",
        "- **더 큰 모델** (BERT-large, GPT 등)\n",
        "- **긴 텍스트** (512 토큰 이상)\n",
        "- **실시간이 아닌 배치 처리**\n",
        "\n",
        "#### **실제 운영 환경에서의 권장사항**\n",
        "\n",
        "1. **개발/테스트**: CPU 사용 (간단하고 빠름)\n",
        "2. **대량 배치 처리**: GPU 사용 (배치 크기 늘려서)\n",
        "3. **실시간 API**: CPU 또는 작은 GPU (지연시간 중요)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
