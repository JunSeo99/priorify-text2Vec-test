# Priorify - 할 일(To-do) 텍스트 카테고리 분류 모델

이 프로젝트는 사용자가 입력한 할 일(To-do) 텍스트를 가장 적절한 카테고리로 자동 분류하는 모델을 개발하고, 다양한 알고리즘의 성능을 비교 분석합니다. **앙상블 기법**과 **파인튜닝**을 통해 단계적으로 성능을 향상시키며, 각 버전별로 특정 문제를 해결하기 위한 접근법을 적용했습니다.

## 🚀 최종 성능 비교 결과

최신 테스트 결과 (전체 1,446개 데이터 기준):

| Algorithm Version                   | Hit Rate @1 | Hit Rate @3 | Hit Rate @5 | F1 (macro) | 개선사항 |
|-------------------------------------|-------------|-------------|-------------|------------|-----------|
| V1 (단순 임베딩)                     | 51.66%      | 77.32%      | 86.58%      | 0.4936     | 기준선 |
| V2 (NER + 앙상블)                    | 60.79%      | 87.62%      | 92.74%      | 0.6065     | **+9.13%p** ⬆️ |
| V3 (NER + 키워드화 + 앙상블)          | 59.89%      | 87.14%      | 92.46%      | 0.6081     | **+8.23%p** ⬆️ |
| **V4 (파인튜닝 + 앙상블)**            | **74.76%**  | **96.33%**  | **98.34%**  | **0.7413** | **+23.1%p** 🚀 |

**핵심 성과**: V1 대비 **23.1%p 향상**으로 실용적인 수준의 정확도 달성

## 🔬 각 버전별 해결 목표 및 기술적 접근

### V1: 기준선 모델 (단순 임베딩)
- **해결 목표**: 기본적인 의미 유사도 기반 분류 성능 측정
- **기술적 접근**: 
  - 한국어 SBERT 모델 (`jhgan/ko-sroberta-multitask`) 사용
  - 단순 카테고리명과 할 일 텍스트 간 코사인 유사도 계산
- **한계**: 단일 임베딩 방식의 제한으로 다양한 표현 방식 커버 불가

### V2: NER + 앙상블 (60.79%)
- **해결 목표**: 개체명 일반화를 통한 패턴 학습 향상 + 다중 임베딩 활용
- **기술적 접근**:
  - **NER 전처리**: `Leo97/KoELECTRA-small-v3-modu-ner`로 인물/장소/조직 일반화
  - **앙상블 구성**: 단순 카테고리명 + 키워드 평균 임베딩
  - **가중치 결정**: 0.5:0.5 균등 가중치 (실험을 통해 최적값 확인)
- **성과**: NER 일반화와 앙상블 효과로 **+9.13%p** 향상

### V3: NER + 키워드화 + 앙상블 (59.89%)
- **해결 목표**: 키워드 기반 의미 표현의 다양성 증대
- **기술적 접근**:
  - **키워드 가중평균**: 키워드 길이 기반 가중치로 구체적 키워드에 높은 중요도
  - **앙상블 구성**: 키워드 평균 + 키워드 가중평균 임베딩
  - **문제 해결**: 초기 키워드 최대값 방식의 의미적 일관성 문제를 가중평균으로 해결
- **성과**: 키워드 표현 개선으로 V1 대비 **+8.23%p** 향상

### V4: 파인튜닝 + 앙상블 (74.76%)
- **해결 목표**: 도메인 특화 학습을 통한 최고 성능 달성
- **기술적 접근**:
  - **파인튜닝 설정**: 3 epochs, Multiple Negatives Ranking Loss
  - **앙상블 평가**: 파인튜닝 중에도 앙상블 성능 실시간 모니터링
  - **최적화**: 앙상블 성능을 기준으로 best model 선택
- **하이퍼파라미터**:
  - Learning Rate: 5e-5 (안정적 학습을 위한 작은 값)
  - Batch Size: 32 (메모리와 성능의 균형)
  - Warmup Ratio: 0.1 (점진적 학습률 증가)
- **성과**: 도메인 특화 학습으로 **최고 성능 74.76%** 달성

## 📂 프로젝트 구조

```
.
├── README.md
├── requirements.txt
├── .gitignore
├── data/
│   └── data.csv                          # 학습/평가 데이터셋 (1,446개)
├── models/
│   └── finetuned_ensemble_v4/            # V4 파인튜닝 모델 (자동 생성)
├── output/                               # 기존 파인튜닝 모델 저장소
├── src/
│   ├── config.py                         # 프로젝트 설정 및 카테고리 정의
│   ├── core/
│   │   └── model_utils.py                # NER 전처리 유틸리티
│   ├── scripts/
│   │   ├── compare_versions.py           # 🎯 V1-V4 성능 비교 (메인 실행 파일)
│   │   ├── finetune.py                   # 🎯 V4 앙상블 파인튜닝 스크립트
│   │   ├── predict.py                    # V4 모델 실시간 예측
│   │   ├── debug_embeddings.py           # 임베딩 방식별 성능 분석
│   │   ├── ensemble_optimization.py      # 앙상블 하이퍼파라미터 최적화
│   │   ├── ensemble_v3_v4.py            # V3/V4 앙상블 실험 및 비교
│   │   ├── evaluate_single_model.py      # 단일 모델 성능 평가
│   │   ├── augment_dataset.py           # 데이터셋 증강 실험
│   │   ├── test_natural_placeholders.py  # NER 플레이스홀더 방식 테스트
│   │   ├── test_ensemble_methods.py      # 다양한 앙상블 기법 실험
│   │   ├── test_placeholder_methods.py   # 플레이스홀더 치환 방법 비교
│   │   ├── test_selective_generalization.py # 선택적 NER 일반화 실험
│   │   ├── test_threshold_optimization.py    # 임계값 최적화 실험
│   │   └── quick_test_v2.py             # V2 빠른 성능 검증
│   └── api/                              # API 관련 파일들
├── Ensemble_Text_Classification_Optimization.ipynb  # Google Colab 실험 노트북
└── google_colab_performance_test.ipynb              # Colab 성능 테스트
```

## 🛠️ 사용 방법

### 1. 환경 설정

```bash
# 1. Python 가상환경 생성 및 활성화
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\\Scripts\\activate    # Windows

# 2. 필요한 패키지 설치
pip install -r requirements.txt
```

### 2. 전체 성능 비교 실행

모든 버전(V1~V4)의 성능을 한 번에 비교하고 최신 결과를 확인:

```bash
python src/scripts/compare_versions.py
```

**실행 결과 예시:**
```
================================================================================
                         알고리즘 버전별 성능 비교 결과
================================================================================
Algorithm Version                   | Hit Rate @1     | Hit Rate @3     | Hit Rate @5     | F1 (macro)  
--------------------------------------------------------------------------------------------------------
V1 (단순 임베딩)                         | 51.66%          | 77.32%          | 86.58%          | 0.4936      
V2 (NER + 앙상블)                      | 60.79%          | 87.62%          | 92.74%          | 0.6065      
V3 (NER + 키워드화 + 앙상블)               | 59.89%          | 87.14%          | 92.46%          | 0.6081      
V4 (파인튜닝 + 앙상블)                     | 74.76%          | 96.33%          | 98.34%          | 0.7413      
================================================================================
```

### 3. 새로운 V4 모델 생성

새로운 파인튜닝 모델을 직접 학습시키고 싶다면:

```bash
python src/scripts/finetune.py
```

### 4. 실시간 예측 테스트

V4 모델로 실시간 예측을 테스트:

```bash
python src/scripts/predict.py
```

## 🔬 실험용 스크립트 상세 설명

각 실험용 스크립트는 특정한 연구 질문이나 최적화 목표를 가지고 개발되었습니다:

### 성능 분석 및 디버깅
- **`debug_embeddings.py`**: 임베딩 방식별 개별 성능 분석 (키워드 평균 vs 최대값 등)
- **`evaluate_single_model.py`**: 특정 모델의 상세 성능 분석 및 오류 케이스 분석

### 앙상블 최적화 실험
- **`ensemble_optimization.py`**: 다양한 가중치 조합에 대한 Grid Search 최적화
- **`ensemble_v3_v4.py`**: V3와 V4의 앙상블 구성 실험 및 성능 비교
- **`test_ensemble_methods.py`**: 가중평균, 최대값, 투표 등 다양한 앙상블 기법 비교

### NER 전처리 최적화
- **`test_natural_placeholders.py`**: 특수토큰 vs 자연어 플레이스홀더 성능 비교
- **`test_placeholder_methods.py`**: 다양한 플레이스홀더 치환 방식 실험
- **`test_selective_generalization.py`**: 선택적 개체명 일반화 효과 분석

### 하이퍼파라미터 튜닝
- **`test_threshold_optimization.py`**: 분류 임계값 최적화 실험
- **`augment_dataset.py`**: 데이터 증강 기법을 통한 성능 향상 실험

### 빠른 검증
- **`quick_test_v2.py`**: V2 알고리즘의 빠른 성능 검증 및 프로토타이핑

이러한 실험들을 통해 최종적으로 **0.5:0.5 앙상블 가중치**, **3 epochs 파인튜닝**, **자연어 플레이스홀더** 등의 최적 설정을 결정했습니다.

## 🔧 핵심 기술 및 하이퍼파라미터

### 앙상블 기법
- **가중치**: 0.5:0.5 균등 가중치 (Grid Search를 통해 최적값 확인)
- **구성**: 서로 다른 임베딩 방식의 조합으로 다양성 확보
- **효과**: 단일 모델 대비 평균 8-12%p 성능 향상

### 파인튜닝 설정
- **에포크**: 3 epochs (과적합 방지)
- **손실 함수**: Multiple Negatives Ranking Loss
- **평가 지표**: 앙상블 Hit Rate @1 기준 최적 모델 선택
- **학습률**: 5e-5 (안정적 수렴을 위한 작은 값)

### NER 전처리
- **모델**: Leo97/KoELECTRA-small-v3-modu-ner
- **일반화 대상**: 인물명, 장소명, 조직명, 날짜, 시간
- **효과**: 고유명사 패턴 일반화로 모델 일반화 성능 향상

이 프로젝트는 단계적 접근을 통해 기본 모델에서 시작해 최종적으로 **74.76%의 실용적 정확도**를 달성했습니다. 각 버전은 특정 문제를 해결하기 위해 설계되었으며, 최종 V4 모델은 실제 서비스에 적용 가능한 수준의 성능을 보여줍니다.
 