# Priorify - 할 일(To-do) 텍스트 카테고리 분류 모델

이 프로젝트는 사용자가 입력한 할 일(To-do) 텍스트를 가장 적절한 카테고리로 자동 분류하는 모델을 개발하고, 다양한 알고리즘의 성능을 비교 분석하는 것을 목표로 합니다.

## 🚀 최종 성능 비교 결과

`data/data.csv` 테스트 데이터셋을 기준으로 V1부터 V4까지의 알고리즘 성능을 다양한 지표로 측정한 최종 결과입니다.

| Algorithm Version            | Hit Rate @1     | Hit Rate @3     | Hit Rate @5     | F1 (macro) |
|------------------------------|-----------------|-----------------|-----------------|------------|
| V1 (단순 유사도)             | 51.47%          | 76.87%          | 85.03%          | 0.5023     |
| V2 (NER 적용)                | 47.01%          | 70.56%          | 78.30%          | 0.4648     |
| V3 (NER+키워드 평균)         | 58.96%          | 81.67%          | 87.05%          | 0.5995     |
| **V4 (NER+키워드+파인튜닝)** | **69.05%**      | **94.03%**      | **97.56%**      | **0.7144** |

**결론**: 도메인 데이터로 파인튜닝하고, NER 일반화 및 키워드 임베딩을 함께 사용한 **V4 모델이 모든 지표에서 가장 뛰어난 성능**을 보여주었습니다. 특히 예측 상위 5개에 정답이 포함될 확률(Hit Rate @5)은 **97.56%** 에 달해 매우 높은 사용성을 기대할 수 있습니다.

## 📂 프로젝트 구조

```
.
├── .gitignore
├── data/
│   └── data.csv              # 모델 학습 및 평가용 데이터셋
├── output/                   # 파인튜닝된 모델 저장 디렉토리 (자동 생성)
├── requirements.txt
├── src/
│   ├── config.py             # 프로젝트 설정 (모델, 경로, 카테고리 정의)
│   ├── core/
│   │   └── model_utils.py    # 핵심 유틸리티 (NER 등)
│   └── scripts/
│       ├── compare_versions.py   # (핵심) V1-V4 알고리즘 성능 비교 스크립트
│       ├── finetune.py           # V4 모델 생성을 위한 파인튜닝 스크립트
│       └── predict.py            # V4 모델을 사용한 실시간 예측 스크립트
└── README.md
```

## 🛠️ 사용 방법

### 1. 환경 설정

```bash
# 1. Python 가상환경 생성 및 활성화
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\\Scripts\\activate    # Windows

# 2. 필요한 패키지 설치
pip install -r requirements.txt
```

### 2. 모델 파인튜닝 (V4 모델 생성)

최고 성능의 V4 모델을 사용하려면, 먼저 `finetune.py`를 실행해 모델을 생성해야 합니다. 이 과정은 몇 분 정도 소요될 수 있습니다.

```bash
python src/scripts/finetune.py
```
*이 과정이 완료되면 `output/finetuned-model` 디렉토리에 모델 파일이 저장됩니다.*


### 3. 실시간 카테고리 예측 (V4 모델 테스트)

방금 만든 V4 모델의 성능을 실시간으로 테스트해볼 수 있습니다. 아래 명령어를 실행하고, 터미널에 할 일 내용을 입력해보세요.

```bash
python src/scripts/predict.py
```

**실행 예시:**
```
$ python src/scripts/predict.py
V4 모델과 관련 리소스를 로딩합니다...
로딩 완료. 예측을 시작할 수 있습니다.

==================================================
      V4 모델을 사용한 할 일 카테고리 예측
==================================================
할 일 내용을 입력해주세요 (종료하려면 'exit' 또는 'quit' 입력)

할 일 입력: 내일 오후 2시에 강남역에서 친구랑 저녁 약속

 > NER 일반화된 텍스트: [DT] [TM]에 [LC]에서 친구랑 저녁 약속

--- 예측 결과 (Top 5) ---
1. 약속/일정         (유사도: 0.8234)
2. 일상             (유사도: 0.5112)
3. 쇼핑             (유사도: 0.4988)
4. 관계             (유사도: 0.4855)
5. 여행/나들이       (유사도: 0.4710)
-----------------------------------
```

### 4. 전체 알고리즘 성능 비교

프로젝트의 핵심 목표였던 V1~V4 알고리즘의 성능을 전체 테스트 데이터셋으로 한 번에 비교하고 싶다면 아래 스크립트를 실행하세요.

```bash
python src/scripts/compare_versions.py
```
스크립트 실행이 완료되면, 맨 위에 있는 최종 성능 비교 결과표가 터미널에 출력됩니다. # priorify-text2Vec-test
# priorify-text2Vec-test
