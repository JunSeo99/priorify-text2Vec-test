{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# 🚀 앙상블 기법을 활용한 한국어 텍스트 분류 최적화\n",
        "\n",
        "이 노트북에서는 다음을 수행합니다:\n",
        "1. **앙상블 하이퍼파라미터 최적화**: 다양한 조합을 테스트하여 최적값 탐색\n",
        "2. **V3 앙상블 적용**: NER + 키워드 평균 임베딩에 앙상블 기법 적용\n",
        "3. **V4 파인튜닝 + 앙상블**: 파인튜닝된 모델에 앙상블 기법 적용\n",
        "\n",
        "## 📊 데이터 사용량\n",
        "- **전체 데이터 활용**: 1,447개의 실제 한국어 텍스트 데이터 사용\n",
        "- **앙상블 평가**: 전체 데이터로 정확한 성능 측정\n",
        "- **파인튜닝**: 800개 데이터로 3 에포크 학습\n",
        "- **하이퍼파라미터 최적화**: 10가지 가중치 조합 테스트\n",
        "\n",
        "## 📋 실행 전 준비사항\n",
        "1. 데이터셋 업로드 (아래 셀에서 안내)\n",
        "2. 패키지 설치 및 환경 설정\n",
        "3. 하드웨어 가속 설정 (GPU 권장)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 환경 설정 및 패키지 설치\n",
        "!pip install sentence-transformers transformers torch scikit-learn pandas numpy tqdm matplotlib seaborn\n",
        "\n",
        "# 하드웨어 확인\n",
        "import torch\n",
        "print(f\"🔍 하드웨어 정보:\")\n",
        "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU 장치: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"GPU 메모리: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
        "print(f\"CPU 코어 수: {torch.get_num_threads()}\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"🎯 사용할 디바이스: {device}\")\n",
        "\n",
        "# 기본 설정\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "\n",
        "# wandb 비활성화 (로그인 없이 실행하기 위함)\n",
        "os.environ['WANDB_DISABLED'] = 'true'\n",
        "print(\"🔕 wandb 추적 비활성화됨 (로그인 불필요)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 📁 데이터셋 준비 방법\n",
        "\n",
        "### 방법 1: 직접 업로드\n",
        "1. 왼쪽 패널의 파일 아이콘 클릭\n",
        "2. `data.csv` 파일을 드래그 앤 드롭으로 업로드\n",
        "\n",
        "### 방법 2: Google Drive 연동\n",
        "```python\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# 파일 경로: /content/drive/MyDrive/your_file.csv\n",
        "```\n",
        "\n",
        "### 방법 3: 샘플 데이터 생성 (테스트용)\n",
        "아래 셀에서 샘플 데이터를 생성할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 샘플 데이터 생성 (실제 데이터가 없는 경우)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def create_sample_data():\n",
        "    \"\"\"테스트용 샘플 데이터 생성\"\"\"\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    # 카테고리별 샘플 텍스트\n",
        "    sample_data = {\n",
        "        '학업': [\n",
        "            '수학 과제 제출하기', '영어 시험 공부하기', '논문 작성하고 발표하기', \n",
        "            '프로젝트 팀 회의 참석하기', '실험실에서 연구하기', '도서관에서 자료 조사하기'\n",
        "        ],\n",
        "        '업무': [\n",
        "            '회의 참석하고 보고서 작성하기', '클라이언트와 미팅하기', '프레젠테이션 준비하기',\n",
        "            '메일 확인하고 답변하기', '새로운 프로젝트 기획하기', '팀원들과 협업하기'\n",
        "        ],\n",
        "        '건강': [\n",
        "            '헬스장에서 운동하기', '병원에서 건강 검진 받기', '요가 클래스 참여하기',\n",
        "            '산책하며 스트레스 해소하기', '충분한 수면 취하기', '건강한 식단 관리하기'\n",
        "        ],\n",
        "        '경제': [\n",
        "            '가계부 정리하고 예산 관리하기', '투자 포트폴리오 점검하기', '적금 넣기',\n",
        "            '부동산 시장 조사하기', '재테크 강의 듣기', '용돈 기입장 작성하기'\n",
        "        ],\n",
        "        '친목': [\n",
        "            '친구들과 카페에서 만나기', '동창회 참석하기', '가족과 저녁 식사하기',\n",
        "            '동료들과 회식하기', '커뮤니티 모임 참여하기', '새로운 사람들과 네트워킹하기'\n",
        "        ],\n",
        "        '취미': [\n",
        "            '독서하며 여가 시간 보내기', '영화 관람하기', '요리 레시피 도전하기',\n",
        "            '여행 계획 세우기', '취미 클래스 수강하기', '온라인 게임 즐기기'\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # 데이터프레임 생성\n",
        "    rows = []\n",
        "    for category, titles in sample_data.items():\n",
        "        for title in titles:\n",
        "            rows.append({'title': title, 'categories': category})\n",
        "    \n",
        "    # 추가 랜덤 데이터 생성\n",
        "    categories = list(sample_data.keys())\n",
        "    for i in range(100):  # 100개 추가 샘플\n",
        "        category = np.random.choice(categories)\n",
        "        title = f\"{category} 관련 활동 {i+1}\"\n",
        "        rows.append({'title': title, 'categories': category})\n",
        "    \n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv('sample_data.csv', index=False)\n",
        "    print(f\"✅ 샘플 데이터 생성 완료: {len(df)}개 항목\")\n",
        "    return df\n",
        "\n",
        "# 실제 데이터 파일이 있는지 확인\n",
        "DATA_PATH = 'data/data.csv'  # 실제 데이터 경로\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    # 대체 경로 확인\n",
        "    if os.path.exists('data.csv'):\n",
        "        DATA_PATH = 'data.csv'\n",
        "    else:\n",
        "        print(\"❌ data.csv 파일을 찾을 수 없습니다.\")\n",
        "        print(\"🔄 샘플 데이터를 생성합니다...\")\n",
        "        df = create_sample_data()\n",
        "        DATA_PATH = 'sample_data.csv'\n",
        "\n",
        "if 'df' not in locals():\n",
        "    print(f\"✅ {DATA_PATH} 파일을 찾았습니다.\")\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    print(f\"📊 전체 데이터: {len(df)}개 항목 로드\")\n",
        "\n",
        "print(f\"📊 데이터 정보: {len(df)}개 행, {len(df.columns)}개 열\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 설정 및 유틸리티 함수\n",
        "from sentence_transformers import SentenceTransformer, util, InputExample, losses, evaluation\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import time\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from itertools import product\n",
        "\n",
        "# 모델 및 설정\n",
        "BASE_MODEL_NAME = 'jhgan/ko-sroberta-multitask'\n",
        "NER_MODEL_NAME = 'Leo97/KoELECTRA-small-v3-modu-ner'\n",
        "\n",
        "# 카테고리 정의 (키워드 기반)\n",
        "CATEGORIES_DEFINITIONS = {\n",
        "    '학업': [\n",
        "        '과제 작성하고 제출하기', '시험 준비하고 공부하기', '연구 활동하고 논문 쓰기',\n",
        "        '실험실에서 연구하기', '세미나 참석하고 발표하기', '도서관에서 자료 찾기',\n",
        "        '프로젝트 팀원과 협업하기', '온라인 강의 수강하기'\n",
        "    ],\n",
        "    '업무': [\n",
        "        '회의 참석하고 의견 제시하기', '보고서 작성하고 검토하기', '클라이언트와 미팅하기',\n",
        "        '프레젠테이션 준비하고 발표하기', '업무 메일 확인하고 답변하기', '새 프로젝트 기획하기',\n",
        "        '동료들과 협업하고 소통하기', '실적 분석하고 개선하기'\n",
        "    ],\n",
        "    '건강': [\n",
        "        '헬스장에서 운동하고 근력 기르기', '병원에서 건강 검진 받기', '요가나 필라테스 하기',\n",
        "        '산책하며 스트레스 해소하기', '충분한 수면 취하고 컨디션 관리하기', '건강한 식단 계획하고 실천하기',\n",
        "        '금연과 금주 실천하기', '정기적인 건강 관리하기'\n",
        "    ],\n",
        "    '경제': [\n",
        "        '가계부 정리하고 지출 관리하기', '투자 포트폴리오 구성하고 관리하기', '적금과 예금 넣기',\n",
        "        '부동산 시장 조사하고 분석하기', '재테크 공부하고 실천하기', '용돈 기입장 작성하기',\n",
        "        '보험 상품 비교하고 가입하기', '세금 신고하고 환급받기'\n",
        "    ],\n",
        "    '친목': [\n",
        "        '친구들과 만나서 대화하기', '동창회나 모임 참석하기', '가족과 시간 보내고 소통하기',\n",
        "        '동료들과 회식하고 친목 도모하기', '새로운 사람들과 네트워킹하기', '커뮤니티 활동 참여하기',\n",
        "        '사회적 관계 유지하고 발전시키기', '지인들과 연락하고 안부 묻기'\n",
        "    ],\n",
        "    '취미': [\n",
        "        '독서하며 지식 쌓고 여가 즐기기', '영화나 드라마 시청하기', '요리 레시피 도전하고 음식 만들기',\n",
        "        '여행 계획 세우고 떠나기', '취미 클래스 수강하고 새 기술 배우기', '게임하며 스트레스 풀기',\n",
        "        '음악 듣고 악기 연주하기', '그림 그리고 창작 활동하기'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# NER 관련 설정\n",
        "NER_SPECIAL_TOKENS = [\"<PERSON>\", \"<LOCATION>\", \"<ORG>\"]\n",
        "V2_IMPROVED_ENTITIES = [\"PS\", \"LC\", \"OG\"]  # 인물, 장소, 조직\n",
        "NER_CONFIDENCE_THRESHOLD = 0.8\n",
        "\n",
        "print(\"✅ 설정 및 카테고리 정의 완료\")\n",
        "print(f\"📝 총 {len(CATEGORIES_DEFINITIONS)}개 카테고리:\")\n",
        "for cat, keywords in CATEGORIES_DEFINITIONS.items():\n",
        "    print(f\"  - {cat}: {len(keywords)}개 키워드\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🧠 NER 모델 로드 및 텍스트 전처리 함수\n",
        "def setup_ner_model():\n",
        "    \"\"\"NER 모델을 설정하고 반환\"\"\"\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(NER_MODEL_NAME)\n",
        "        model = AutoModelForTokenClassification.from_pretrained(NER_MODEL_NAME)\n",
        "        ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0 if device == \"cuda\" else -1)\n",
        "        print(\"✅ NER 모델 로드 완료\")\n",
        "        return ner_pipeline\n",
        "    except Exception as e:\n",
        "        print(f\"❌ NER 모델 로드 실패: {e}\")\n",
        "        return None\n",
        "\n",
        "def ner_generalize_texts(texts, entities_to_generalize=V2_IMPROVED_ENTITIES, confidence_threshold=NER_CONFIDENCE_THRESHOLD):\n",
        "    \"\"\"NER을 사용하여 텍스트 일반화\"\"\"\n",
        "    ner_pipeline = setup_ner_model()\n",
        "    if not ner_pipeline:\n",
        "        return texts  # NER 실패시 원본 반환\n",
        "    \n",
        "    generalized_texts = []\n",
        "    \n",
        "    for text in tqdm(texts, desc=\"NER 일반화 진행\"):\n",
        "        try:\n",
        "            # NER 수행\n",
        "            entities = ner_pipeline(text)\n",
        "            \n",
        "            # 신뢰도 기준으로 필터링\n",
        "            filtered_entities = [\n",
        "                entity for entity in entities\n",
        "                if entity['score'] >= confidence_threshold and \n",
        "                entity['entity'].replace('B-', '').replace('I-', '') in entities_to_generalize\n",
        "            ]\n",
        "            \n",
        "            # 엔티티를 위치 순으로 정렬 (뒤에서부터 치환하기 위해 역순)\n",
        "            filtered_entities.sort(key=lambda x: x['start'], reverse=True)\n",
        "            \n",
        "            # 텍스트 치환\n",
        "            generalized_text = text\n",
        "            for entity in filtered_entities:\n",
        "                entity_type = entity['entity'].replace('B-', '').replace('I-', '')\n",
        "                if entity_type == 'PS':\n",
        "                    replacement = '<PERSON>'\n",
        "                elif entity_type == 'LC':\n",
        "                    replacement = '<LOCATION>'\n",
        "                elif entity_type == 'OG':\n",
        "                    replacement = '<ORG>'\n",
        "                else:\n",
        "                    continue\n",
        "                \n",
        "                generalized_text = (\n",
        "                    generalized_text[:entity['start']] + \n",
        "                    replacement + \n",
        "                    generalized_text[entity['end']:]\n",
        "                )\n",
        "            \n",
        "            generalized_texts.append(generalized_text)\n",
        "            \n",
        "        except Exception as e:\n",
        "            # 오류 발생시 원본 텍스트 사용\n",
        "            generalized_texts.append(text)\n",
        "    \n",
        "    return generalized_texts\n",
        "\n",
        "print(\"✅ NER 전처리 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 앙상블 최적화 클래스\n",
        "class EnsembleOptimizer:\n",
        "    \"\"\"앙상블 기법의 하이퍼파라미터를 최적화하는 클래스\"\"\"\n",
        "    \n",
        "    def __init__(self, data_path, sample_size=None):\n",
        "        self.data_path = data_path\n",
        "        self.sample_size = sample_size  # None이면 전체 데이터 사용\n",
        "        \n",
        "        # 카테고리 정의 (가장 먼저 설정)\n",
        "        self.categories = list(CATEGORIES_DEFINITIONS.keys())\n",
        "        \n",
        "        # 모델 로드\n",
        "        print(\"🔄 모델 로딩 중...\")\n",
        "        self.base_model = SentenceTransformer(BASE_MODEL_NAME, device=device)\n",
        "        \n",
        "        # 데이터 준비\n",
        "        self.test_df = self._prepare_data()\n",
        "        \n",
        "        # 기본 임베딩들 미리 계산\n",
        "        self._precompute_embeddings()\n",
        "        \n",
        "    def _prepare_data(self):\n",
        "        \"\"\"데이터 로드 및 전처리\"\"\"\n",
        "        df = pd.read_csv(self.data_path)\n",
        "        \n",
        "        # 카테고리 컬럼 정규화\n",
        "        if 'categories' not in df.columns and 'category' in df.columns:\n",
        "            df = df.rename(columns={'category': 'categories'})\n",
        "        \n",
        "        df.dropna(subset=['title', 'categories'], inplace=True)\n",
        "        df['category'] = df['categories'].apply(lambda x: x.split(';')[0].strip() if isinstance(x, str) else x)\n",
        "        df = df[df['category'].isin(self.categories)]\n",
        "        \n",
        "        # 샘플링 (sample_size가 None이면 전체 데이터 사용)\n",
        "        if self.sample_size is not None and len(df) > self.sample_size:\n",
        "            df = df.sample(n=self.sample_size, random_state=42)\n",
        "            print(f\"⚡ 빠른 실행을 위해 {self.sample_size}개 샘플로 제한\")\n",
        "        else:\n",
        "            print(f\"📊 전체 데이터 사용: {len(df)}개\")\n",
        "        \n",
        "        # NER 전처리\n",
        "        print(\"🔄 NER 전처리 중...\")\n",
        "        df = df.copy()\n",
        "        df['generalized_title'] = ner_generalize_texts(df['title'].tolist())\n",
        "        \n",
        "        print(f\"✅ 테스트 데이터 준비 완료: {len(df)}개\")\n",
        "        return df\n",
        "    \n",
        "    def _precompute_embeddings(self):\n",
        "        \"\"\"기본 임베딩들을 미리 계산\"\"\"\n",
        "        print(\"🔄 기본 임베딩 계산 중...\")\n",
        "        \n",
        "        # 단순 카테고리명 임베딩\n",
        "        self.simple_cat_embs = self.base_model.encode(\n",
        "            self.categories, \n",
        "            convert_to_tensor=True, \n",
        "            normalize_embeddings=True\n",
        "        )\n",
        "        \n",
        "        # 키워드 평균 임베딩\n",
        "        self.keyword_avg_embs = self._get_keyword_avg_embs()\n",
        "        \n",
        "        print(\"✅ 기본 임베딩 계산 완료\")\n",
        "    \n",
        "    def _get_keyword_avg_embs(self):\n",
        "        \"\"\"카테고리별 키워드 평균 임베딩 계산\"\"\"\n",
        "        category_embs = {}\n",
        "        for category, keywords in CATEGORIES_DEFINITIONS.items():\n",
        "            keyword_embs = self.base_model.encode(keywords, convert_to_numpy=True, normalize_embeddings=True)\n",
        "            avg_emb = np.mean(keyword_embs, axis=0)\n",
        "            if np.linalg.norm(avg_emb) > 0:\n",
        "                avg_emb = avg_emb / np.linalg.norm(avg_emb)\n",
        "            category_embs[category] = avg_emb\n",
        "        return torch.tensor(np.array(list(category_embs.values()))).to(device)\n",
        "\n",
        "print(\"✅ 앙상블 최적화 클래스 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔍 앙상블 평가 메소드들 추가 (기존 클래스에 메소드 추가)\n",
        "def _ensemble_predict(self, ensemble_configs, text_column='generalized_title'):\n",
        "    \"\"\"앙상블 예측 수행\"\"\"\n",
        "    all_similarities = []\n",
        "    weights = []\n",
        "    \n",
        "    for config in ensemble_configs:\n",
        "        model_type = config['model']\n",
        "        embedding_type = config['embedding']\n",
        "        weight = config['weight']\n",
        "        \n",
        "        # 모델 선택 (여기서는 base 모델만 사용)\n",
        "        model = self.base_model\n",
        "        \n",
        "        # 임베딩 타입에 따른 카테고리 임베딩 선택\n",
        "        if embedding_type == 'simple':\n",
        "            category_embs = self.simple_cat_embs\n",
        "        elif embedding_type == 'keyword_avg':\n",
        "            category_embs = self.keyword_avg_embs\n",
        "        else:\n",
        "            continue\n",
        "            \n",
        "        # 텍스트 임베딩 계산\n",
        "        text_embs = model.encode(\n",
        "            self.test_df[text_column].tolist(), \n",
        "            convert_to_tensor=True, \n",
        "            normalize_embeddings=True\n",
        "        )\n",
        "        \n",
        "        # 유사도 계산\n",
        "        similarities = util.cos_sim(text_embs, category_embs).cpu().numpy()\n",
        "        all_similarities.append(similarities)\n",
        "        weights.append(weight)\n",
        "    \n",
        "    if not all_similarities:\n",
        "        return None\n",
        "    \n",
        "    # 가중 평균으로 앙상블\n",
        "    weights = np.array(weights)\n",
        "    weights = weights / weights.sum()  # 정규화\n",
        "    \n",
        "    ensemble_similarities = np.zeros_like(all_similarities[0])\n",
        "    for sim, w in zip(all_similarities, weights):\n",
        "        ensemble_similarities += sim * w\n",
        "        \n",
        "    return ensemble_similarities\n",
        "\n",
        "def _evaluate_ensemble(self, ensemble_configs, text_column='generalized_title'):\n",
        "    \"\"\"앙상블 성능 평가\"\"\"\n",
        "    similarities = self._ensemble_predict(ensemble_configs, text_column)\n",
        "    if similarities is None:\n",
        "        return {}\n",
        "    \n",
        "    # 예측 결과 계산\n",
        "    pred_indices = np.argsort(similarities, axis=1)[:, ::-1]  # 내림차순 정렬\n",
        "    \n",
        "    true_categories = self.test_df['category'].tolist()\n",
        "    true_indices = [self.categories.index(cat) for cat in true_categories]\n",
        "    \n",
        "    # Hit Rate 계산\n",
        "    correct_at_1 = sum(1 for i, true_idx in enumerate(true_indices) if true_idx == pred_indices[i, 0])\n",
        "    correct_at_3 = sum(1 for i, true_idx in enumerate(true_indices) if true_idx in pred_indices[i, :3])\n",
        "    \n",
        "    total_count = len(self.test_df)\n",
        "    hit_rate_1 = correct_at_1 / total_count\n",
        "    hit_rate_3 = correct_at_3 / total_count\n",
        "    \n",
        "    # F1-score 계산\n",
        "    top_1_predictions = [self.categories[idx] for idx in pred_indices[:, 0]]\n",
        "    _, _, f1, _ = precision_recall_fscore_support(\n",
        "        true_categories, top_1_predictions, average='macro', zero_division=0\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'hit_rate_1': hit_rate_1,\n",
        "        'hit_rate_3': hit_rate_3,\n",
        "        'f1_score': f1\n",
        "    }\n",
        "\n",
        "# 클래스에 메소드 추가\n",
        "EnsembleOptimizer._ensemble_predict = _ensemble_predict\n",
        "EnsembleOptimizer._evaluate_ensemble = _evaluate_ensemble\n",
        "\n",
        "print(\"✅ 앙상블 평가 메소드 추가 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔧 하이퍼파라미터 최적화 메소드 (기존 클래스에 메소드 추가)\n",
        "def optimize_hyperparameters(self):\n",
        "    \"\"\"앙상블 하이퍼파라미터 최적화\"\"\"\n",
        "    print(\"🚀 앙상블 하이퍼파라미터 최적화 시작\")\n",
        "    \n",
        "    # 최적화할 하이퍼파라미터 정의 (전체 데이터 활용으로 확장)\n",
        "    ensemble_sizes = [2, 3]  # 앙상블 구성요소 개수\n",
        "    weight_combinations = [\n",
        "        # 2-way 앙상블\n",
        "        [0.5, 0.5],\n",
        "        [0.6, 0.4],\n",
        "        [0.7, 0.3],\n",
        "        [0.8, 0.2],\n",
        "        [0.4, 0.6],\n",
        "        [0.3, 0.7],\n",
        "        # 3-way 앙상블 (향후 확장용)\n",
        "        [0.4, 0.3, 0.3],\n",
        "        [0.5, 0.3, 0.2],\n",
        "        [0.6, 0.3, 0.1],\n",
        "        [0.33, 0.33, 0.34]\n",
        "    ]\n",
        "    \n",
        "    # 기본 구성요소들\n",
        "    base_components = [\n",
        "        {'model': 'base', 'embedding': 'simple'},\n",
        "        {'model': 'base', 'embedding': 'keyword_avg'}\n",
        "    ]\n",
        "    \n",
        "    best_results = {}\n",
        "    best_configs = {}\n",
        "    \n",
        "    print(f\"📊 총 {len(weight_combinations)}개 조합 테스트\")\n",
        "    \n",
        "    for i, weights in enumerate(weight_combinations):\n",
        "        ensemble_size = len(weights)\n",
        "        if ensemble_size > len(base_components):\n",
        "            continue\n",
        "            \n",
        "        # 앙상블 구성 생성\n",
        "        ensemble_config = []\n",
        "        for j in range(ensemble_size):\n",
        "            config = base_components[j].copy()\n",
        "            config['weight'] = weights[j]\n",
        "            ensemble_config.append(config)\n",
        "        \n",
        "        # 평가 수행\n",
        "        print(f\"\\\\n🔄 조합 {i+1}/{len(weight_combinations)} 테스트 중...\")\n",
        "        print(f\"   구성: {ensemble_config}\")\n",
        "        \n",
        "        results = self._evaluate_ensemble(ensemble_config)\n",
        "        if not results:\n",
        "            continue\n",
        "        \n",
        "        # 최고 성능 업데이트\n",
        "        for metric in ['hit_rate_1', 'hit_rate_3', 'f1_score']:\n",
        "            if metric not in best_results or results[metric] > best_results[metric]:\n",
        "                best_results[metric] = results[metric]\n",
        "                best_configs[metric] = {\n",
        "                    'config': ensemble_config,\n",
        "                    'results': results\n",
        "                }\n",
        "        \n",
        "        print(f\"   결과: Hit@1={results['hit_rate_1']:.3f}, Hit@3={results['hit_rate_3']:.3f}, F1={results['f1_score']:.3f}\")\n",
        "    \n",
        "    return best_configs, best_results\n",
        "\n",
        "def run_baseline_comparison(self):\n",
        "    \"\"\"기본 버전들과 성능 비교\"\"\"\n",
        "    print(\"\\\\n📊 기본 버전들 성능 측정\")\n",
        "    \n",
        "    baselines = {}\n",
        "    \n",
        "    # V1: 단순 카테고리명 매칭\n",
        "    print(\"🔄 V1 (단순 카테고리명) 평가 중...\")\n",
        "    baselines['V1'] = self._evaluate_single_method('simple', 'title')\n",
        "    \n",
        "    # V2: NER + 단순 카테고리명\n",
        "    print(\"🔄 V2 (NER + 단순 카테고리명) 평가 중...\")\n",
        "    baselines['V2'] = self._evaluate_single_method('simple', 'generalized_title')\n",
        "    \n",
        "    # V3: NER + 키워드 평균\n",
        "    print(\"🔄 V3 (NER + 키워드 평균) 평가 중...\")\n",
        "    baselines['V3'] = self._evaluate_single_method('keyword_avg', 'generalized_title')\n",
        "    \n",
        "    return baselines\n",
        "\n",
        "def _evaluate_single_method(self, embedding_type, text_column):\n",
        "    \"\"\"단일 방법 평가\"\"\"\n",
        "    config = [{'model': 'base', 'embedding': embedding_type, 'weight': 1.0}]\n",
        "    return self._evaluate_ensemble(config, text_column)\n",
        "\n",
        "# 클래스에 메소드 추가\n",
        "EnsembleOptimizer.optimize_hyperparameters = optimize_hyperparameters\n",
        "EnsembleOptimizer.run_baseline_comparison = run_baseline_comparison\n",
        "EnsembleOptimizer._evaluate_single_method = _evaluate_single_method\n",
        "\n",
        "print(\"✅ 하이퍼파라미터 최적화 메소드 추가 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 결과 시각화 및 출력 함수\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_results(baselines, best_ensemble_results, title=\"성능 비교\"):\n",
        "    \"\"\"결과를 시각화\"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    \n",
        "    # 데이터 준비\n",
        "    methods = list(baselines.keys()) + ['Ensemble (Best)']\n",
        "    hit_rate_1_scores = [baselines[method]['hit_rate_1'] for method in baselines.keys()]\n",
        "    hit_rate_3_scores = [baselines[method]['hit_rate_3'] for method in baselines.keys()]\n",
        "    f1_scores = [baselines[method]['f1_score'] for method in baselines.keys()]\n",
        "    \n",
        "    # 최고 앙상블 성능 추가\n",
        "    if 'hit_rate_1' in best_ensemble_results:\n",
        "        hit_rate_1_scores.append(best_ensemble_results['hit_rate_1'])\n",
        "        hit_rate_3_scores.append(best_ensemble_results['hit_rate_3'])\n",
        "        f1_scores.append(best_ensemble_results['f1_score'])\n",
        "    \n",
        "    # 서브플롯 생성\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    \n",
        "    # Hit Rate @1\n",
        "    axes[0].bar(methods, hit_rate_1_scores, color='skyblue', alpha=0.8)\n",
        "    axes[0].set_title('Hit Rate @1')\n",
        "    axes[0].set_ylabel('Accuracy')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Hit Rate @3\n",
        "    axes[1].bar(methods, hit_rate_3_scores, color='lightcoral', alpha=0.8)\n",
        "    axes[1].set_title('Hit Rate @3')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # F1 Score\n",
        "    axes[2].bar(methods, f1_scores, color='lightgreen', alpha=0.8)\n",
        "    axes[2].set_title('F1 Score (Macro)')\n",
        "    axes[2].set_ylabel('F1 Score')\n",
        "    axes[2].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(title, y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "def print_detailed_results(baselines, best_configs, best_results):\n",
        "    \"\"\"상세 결과 출력\"\"\"\n",
        "    print(\"\\\\n\" + \"=\"*80)\n",
        "    print(\" \" * 25 + \"🏆 최종 성능 비교 결과\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # 기본 버전들 결과\n",
        "    print(\"\\\\n📈 기본 버전들 성능:\")\n",
        "    for method, results in baselines.items():\n",
        "        print(f\"  {method:15} | Hit@1: {results['hit_rate_1']:.3f} | Hit@3: {results['hit_rate_3']:.3f} | F1: {results['f1_score']:.3f}\")\n",
        "    \n",
        "    # 최고 앙상블 결과\n",
        "    print(\"\\\\n🔥 최고 앙상블 성능:\")\n",
        "    for metric, value in best_results.items():\n",
        "        print(f\"  {metric:15} | {value:.3f}\")\n",
        "    \n",
        "    # 최적 설정 출력\n",
        "    print(\"\\\\n⚙️ 최적 앙상블 설정:\")\n",
        "    for metric, config_info in best_configs.items():\n",
        "        print(f\"\\\\n📊 {metric} 최적 설정:\")\n",
        "        print(f\"   구성: {config_info['config']}\")\n",
        "        print(f\"   성능: {config_info['results']}\")\n",
        "\n",
        "print(\"✅ 시각화 및 출력 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 V3 앙상블 최적화 실행\n",
        "print(\"=\"*80)\n",
        "print(\" \" * 20 + \"🔬 V3 앙상블 기법 최적화 실험\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 앙상블 최적화 인스턴스 생성 (전체 데이터 사용)\n",
        "optimizer = EnsembleOptimizer(DATA_PATH, sample_size=None)  # 전체 데이터 사용\n",
        "\n",
        "# 기본 버전들 성능 측정\n",
        "print(\"\\\\n1️⃣ 기본 버전들(V1, V2, V3) 성능 측정\")\n",
        "baselines = optimizer.run_baseline_comparison()\n",
        "\n",
        "# 앙상블 하이퍼파라미터 최적화\n",
        "print(\"\\\\n\\\\n2️⃣ 앙상블 하이퍼파라미터 최적화\")\n",
        "best_configs, best_results = optimizer.optimize_hyperparameters()\n",
        "\n",
        "# 결과 시각화\n",
        "print(\"\\\\n\\\\n3️⃣ 결과 시각화\")\n",
        "plot_results(baselines, best_results, \"V3 vs 앙상블 성능 비교\")\n",
        "\n",
        "# 상세 결과 출력\n",
        "print_detailed_results(baselines, best_configs, best_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 🔧 V4: 파인튜닝 + 앙상블 기법\n",
        "\n",
        "V3의 앙상블 결과가 좋다면, 이제 파인튜닝을 추가로 적용해보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎓 파인튜닝 클래스 정의\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class QuickFinetuner:\n",
        "    \"\"\"한국어 텍스트 분류를 위한 파인튜닝 클래스\"\"\"\n",
        "    \n",
        "    def __init__(self, data_path, sample_size=500):\n",
        "        self.data_path = data_path\n",
        "        self.sample_size = sample_size  # 기본값을 500으로 증가\n",
        "        self.categories_definitions = CATEGORIES_DEFINITIONS\n",
        "        self.categories = list(CATEGORIES_DEFINITIONS.keys())  # categories 속성 추가\n",
        "        \n",
        "        # 데이터 준비\n",
        "        self.train_df, self.test_df = self._prepare_data()\n",
        "        \n",
        "    def _prepare_data(self):\n",
        "        \"\"\"파인튜닝용 데이터 준비\"\"\"\n",
        "        df = pd.read_csv(self.data_path)\n",
        "        \n",
        "        # 카테고리 컬럼 정규화\n",
        "        if 'categories' not in df.columns and 'category' in df.columns:\n",
        "            df = df.rename(columns={'category': 'categories'})\n",
        "        \n",
        "        df.dropna(subset=['title', 'categories'], inplace=True)\n",
        "        df['category'] = df['categories'].apply(lambda x: x.split(';')[0].strip() if isinstance(x, str) else x)\n",
        "        df = df[df['category'].isin(list(CATEGORIES_DEFINITIONS.keys()))]\n",
        "        \n",
        "        # 파인튜닝용 데이터 샘플링\n",
        "        if len(df) > self.sample_size:\n",
        "            df = df.sample(n=self.sample_size, random_state=42)\n",
        "            print(f\"📊 파인튜닝용 데이터: {self.sample_size}개 (전체 {len(df)}개에서 샘플링)\")\n",
        "        else:\n",
        "            print(f\"📊 전체 데이터 사용: {len(df)}개\")\n",
        "        \n",
        "        # 훈련/테스트 분할\n",
        "        train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "        \n",
        "        # NER 전처리\n",
        "        train_df = train_df.copy()\n",
        "        test_df = test_df.copy()\n",
        "        train_df['generalized_title'] = ner_generalize_texts(train_df['title'].tolist())\n",
        "        test_df['generalized_title'] = ner_generalize_texts(test_df['title'].tolist())\n",
        "        \n",
        "        print(f\"✅ 파인튜닝 데이터 준비: 훈련 {len(train_df)}개, 테스트 {len(test_df)}개\")\n",
        "        return train_df, test_df\n",
        "    \n",
        "    def create_training_examples(self):\n",
        "        \"\"\"파인튜닝용 InputExample 생성\"\"\"\n",
        "        examples = []\n",
        "        for _, row in self.train_df.iterrows():\n",
        "            title = row['generalized_title']\n",
        "            category = row['category']\n",
        "            \n",
        "            # 해당 카테고리의 키워드들과 positive example 생성\n",
        "            if category in self.categories_definitions:\n",
        "                for keyword in self.categories_definitions[category]:\n",
        "                    examples.append(InputExample(texts=[title, keyword]))\n",
        "        \n",
        "        print(f\"✅ 파인튜닝 예시 생성: {len(examples)}개\")\n",
        "        return examples\n",
        "\n",
        "print(\"✅ 파인튜닝 클래스 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 V4 파인튜닝 실행 (조건부)\n",
        "print(\"\\\\n\" + \"=\"*80)\n",
        "print(\" \" * 15 + \"🎓 V4: 파인튜닝 + 앙상블 기법 적용\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# V3 앙상블 결과가 기본 V3보다 좋은지 확인\n",
        "v3_baseline = baselines['V3']['hit_rate_1']\n",
        "best_ensemble_hit1 = best_results.get('hit_rate_1', 0)\n",
        "\n",
        "print(f\"\\\\n📊 성능 비교:\")\n",
        "print(f\"  V3 기본: {v3_baseline:.3f}\")\n",
        "print(f\"  V3 앙상블: {best_ensemble_hit1:.3f}\")\n",
        "print(f\"  향상도: {((best_ensemble_hit1 - v3_baseline) / v3_baseline * 100):.1f}%\")\n",
        "\n",
        "# 앙상블이 향상되었다면 파인튜닝도 적용\n",
        "if best_ensemble_hit1 > v3_baseline:\n",
        "    print(\"\\\\n✅ 앙상블 기법이 성능을 향상시켰습니다!\")\n",
        "    print(\"🔄 V4 파인튜닝을 진행합니다...\")\n",
        "    \n",
        "    # 파인튜닝 실행 (더 많은 데이터 사용)\n",
        "    finetuner = QuickFinetuner(DATA_PATH, sample_size=800)  # 전체 데이터의 절반 정도 사용\n",
        "    \n",
        "    # 파인튜닝 (더 많은 에포크로 향상된 학습)\n",
        "    print(\"\\\\n🎓 파인튜닝 실행 중... (3 epochs)\")\n",
        "    finetuned_model = finetuner.quick_finetune(epochs=3)\n",
        "    \n",
        "    print(\"✅ V4 파인튜닝 완료!\")\n",
        "    \n",
        "else:\n",
        "    print(\"\\\\n❌ 앙상블 기법이 큰 향상을 보이지 않았습니다.\")\n",
        "    print(\"파인튜닝을 건너뜁니다.\")\n",
        "    finetuned_model = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔄 파인튜닝 메소드 추가\n",
        "class QuickFinetuner(QuickFinetuner):  # 클래스 확장\n",
        "    \n",
        "    def quick_finetune(self, epochs=1):\n",
        "        \"\"\"빠른 파인튜닝 수행\"\"\"\n",
        "        print(\"🔄 파인튜닝 시작...\")\n",
        "        \n",
        "        # wandb 비활성화 확인\n",
        "        os.environ['WANDB_DISABLED'] = 'true'\n",
        "        \n",
        "        # 모델 로드\n",
        "        model = SentenceTransformer(BASE_MODEL_NAME, device=device)\n",
        "        \n",
        "        # 특수 토큰 추가\n",
        "        model.tokenizer.add_special_tokens({\"additional_special_tokens\": NER_SPECIAL_TOKENS})\n",
        "        model._first_module().auto_model.resize_token_embeddings(len(model.tokenizer))\n",
        "        \n",
        "        # 훈련 예시 생성\n",
        "        train_examples = self.create_training_examples()\n",
        "        \n",
        "        # 데이터로더 생성\n",
        "        train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=8)\n",
        "        \n",
        "        # 손실 함수\n",
        "        train_loss = losses.MultipleNegativesRankingLoss(model)\n",
        "        \n",
        "        # 훈련 실행\n",
        "        model.fit(\n",
        "            train_objectives=[(train_dataloader, train_loss)],\n",
        "            epochs=epochs,\n",
        "            warmup_steps=max(1, int(len(train_dataloader) * 0.1)),\n",
        "            show_progress_bar=True\n",
        "        )\n",
        "        \n",
        "        print(\"✅ 파인튜닝 완료\")\n",
        "        return model\n",
        "\n",
        "print(\"✅ 파인튜닝 메소드 추가 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 V4 앙상블 평가 (파인튜닝된 모델 포함)\n",
        "if finetuned_model is not None:\n",
        "    print(\"\\\\n\" + \"=\"*60)\n",
        "    print(\" \" * 15 + \"🔥 V4 앙상블 평가\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # 파인튜닝된 모델로 V4 앙상블 평가\n",
        "    class V4EnsembleEvaluator:\n",
        "        \"\"\"V4용 앙상블 평가기\"\"\"\n",
        "        \n",
        "        def __init__(self, test_df, base_model, finetuned_model):\n",
        "            self.test_df = test_df\n",
        "            self.base_model = base_model\n",
        "            self.finetuned_model = finetuned_model\n",
        "            self.categories = list(CATEGORIES_DEFINITIONS.keys())\n",
        "            \n",
        "            # 파인튜닝된 모델의 카테고리 임베딩 계산\n",
        "            self.finetuned_keyword_embs = self._get_keyword_avg_embs(finetuned_model)\n",
        "            self.base_keyword_embs = self._get_keyword_avg_embs(base_model)\n",
        "            \n",
        "        def _get_keyword_avg_embs(self, model):\n",
        "            \"\"\"키워드 평균 임베딩 계산\"\"\"\n",
        "            category_embs = {}\n",
        "            for category, keywords in CATEGORIES_DEFINITIONS.items():\n",
        "                keyword_embs = model.encode(keywords, convert_to_numpy=True, normalize_embeddings=True)\n",
        "                avg_emb = np.mean(keyword_embs, axis=0)\n",
        "                if np.linalg.norm(avg_emb) > 0:\n",
        "                    avg_emb = avg_emb / np.linalg.norm(avg_emb)\n",
        "                category_embs[category] = avg_emb\n",
        "            return torch.tensor(np.array(list(category_embs.values()))).to(device)\n",
        "        \n",
        "        def evaluate_v4_ensemble(self, ensemble_config):\n",
        "            \"\"\"V4 앙상블 평가\"\"\"\n",
        "            all_similarities = []\n",
        "            weights = []\n",
        "            \n",
        "            for config in ensemble_config:\n",
        "                model_type = config['model']\n",
        "                embedding_type = config['embedding']\n",
        "                weight = config['weight']\n",
        "                \n",
        "                # 모델 선택\n",
        "                if model_type == 'base':\n",
        "                    model = self.base_model\n",
        "                    category_embs = self.base_keyword_embs\n",
        "                elif model_type == 'finetuned':\n",
        "                    model = self.finetuned_model\n",
        "                    category_embs = self.finetuned_keyword_embs\n",
        "                else:\n",
        "                    continue\n",
        "                \n",
        "                # 텍스트 임베딩\n",
        "                text_embs = model.encode(\n",
        "                    self.test_df['generalized_title'].tolist(),\n",
        "                    convert_to_tensor=True,\n",
        "                    normalize_embeddings=True\n",
        "                )\n",
        "                \n",
        "                # 유사도 계산\n",
        "                similarities = util.cos_sim(text_embs, category_embs).cpu().numpy()\n",
        "                all_similarities.append(similarities)\n",
        "                weights.append(weight)\n",
        "            \n",
        "            # 앙상블 계산\n",
        "            if not all_similarities:\n",
        "                return {}\n",
        "            \n",
        "            weights = np.array(weights) / np.sum(weights)\n",
        "            ensemble_similarities = np.zeros_like(all_similarities[0])\n",
        "            for sim, w in zip(all_similarities, weights):\n",
        "                ensemble_similarities += sim * w\n",
        "            \n",
        "            # 성능 계산\n",
        "            pred_indices = np.argsort(ensemble_similarities, axis=1)[:, ::-1]\n",
        "            true_categories = self.test_df['category'].tolist()\n",
        "            true_indices = [self.categories.index(cat) for cat in true_categories]\n",
        "            \n",
        "            correct_at_1 = sum(1 for i, true_idx in enumerate(true_indices) if true_idx == pred_indices[i, 0])\n",
        "            correct_at_3 = sum(1 for i, true_idx in enumerate(true_indices) if true_idx in pred_indices[i, :3])\n",
        "            \n",
        "            total_count = len(self.test_df)\n",
        "            hit_rate_1 = correct_at_1 / total_count\n",
        "            hit_rate_3 = correct_at_3 / total_count\n",
        "            \n",
        "            # F1 계산\n",
        "            top_1_predictions = [self.categories[idx] for idx in pred_indices[:, 0]]\n",
        "            _, _, f1, _ = precision_recall_fscore_support(\n",
        "                true_categories, top_1_predictions, average='macro', zero_division=0\n",
        "            )\n",
        "            \n",
        "            return {\n",
        "                'hit_rate_1': hit_rate_1,\n",
        "                'hit_rate_3': hit_rate_3,\n",
        "                'f1_score': f1\n",
        "            }\n",
        "    \n",
        "    # V4 평가 실행\n",
        "    v4_evaluator = V4EnsembleEvaluator(optimizer.test_df, optimizer.base_model, finetuned_model)\n",
        "    \n",
        "    # 여러 V4 앙상블 구성 테스트\n",
        "    v4_configs = [\n",
        "        # Base + Finetuned 조합\n",
        "        [\n",
        "            {'model': 'base', 'embedding': 'keyword_avg', 'weight': 0.4},\n",
        "            {'model': 'finetuned', 'embedding': 'keyword_avg', 'weight': 0.6}\n",
        "        ],\n",
        "        [\n",
        "            {'model': 'base', 'embedding': 'keyword_avg', 'weight': 0.3},\n",
        "            {'model': 'finetuned', 'embedding': 'keyword_avg', 'weight': 0.7}\n",
        "        ],\n",
        "        [\n",
        "            {'model': 'base', 'embedding': 'keyword_avg', 'weight': 0.5},\n",
        "            {'model': 'finetuned', 'embedding': 'keyword_avg', 'weight': 0.5}\n",
        "        ]\n",
        "    ]\n",
        "    \n",
        "    print(\"\\\\n🔍 V4 앙상블 구성 테스트:\")\n",
        "    v4_results = {}\n",
        "    \n",
        "    for i, config in enumerate(v4_configs):\n",
        "        result = v4_evaluator.evaluate_v4_ensemble(config)\n",
        "        v4_results[f'V4_Config_{i+1}'] = result\n",
        "        print(f\"\\\\n구성 {i+1}: {config}\")\n",
        "        print(f\"결과: Hit@1={result['hit_rate_1']:.3f}, Hit@3={result['hit_rate_3']:.3f}, F1={result['f1_score']:.3f}\")\n",
        "    \n",
        "    # 최고 V4 결과 찾기\n",
        "    best_v4 = max(v4_results.items(), key=lambda x: x[1]['hit_rate_1'])\n",
        "    print(f\"\\\\n🏆 최고 V4 성능: {best_v4[0]} - Hit@1: {best_v4[1]['hit_rate_1']:.3f}\")\n",
        "    \n",
        "else:\n",
        "    print(\"\\\\n⏭️ 파인튜닝이 수행되지 않아 V4 평가를 건너뜁니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📈 최종 결과 종합 및 시각화\n",
        "print(\"\\\\n\" + \"=\"*80)\n",
        "print(\" \" * 20 + \"🏆 최종 종합 결과\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 모든 결과 통합\n",
        "all_results = {\n",
        "    'V1 (기본)': baselines['V1'],\n",
        "    'V2 (NER)': baselines['V2'], \n",
        "    'V3 (NER+키워드)': baselines['V3'],\n",
        "    'V3 앙상블': {\n",
        "        'hit_rate_1': best_results.get('hit_rate_1', 0),\n",
        "        'hit_rate_3': best_results.get('hit_rate_3', 0),\n",
        "        'f1_score': best_results.get('f1_score', 0)\n",
        "    }\n",
        "}\n",
        "\n",
        "# V4 결과가 있다면 추가\n",
        "if finetuned_model is not None and 'best_v4' in locals():\n",
        "    all_results['V4 (파인튜닝+앙상블)'] = best_v4[1]\n",
        "\n",
        "# 최종 성능 표 출력\n",
        "print(\"\\\\n📊 성능 비교표:\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'방법':<20} {'Hit@1':<10} {'Hit@3':<10} {'F1-Score':<10} {'향상도':<10}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "baseline_hit1 = baselines['V1']['hit_rate_1']  # V1을 기준으로 향상도 계산\n",
        "\n",
        "for method, results in all_results.items():\n",
        "    hit1 = results['hit_rate_1']\n",
        "    hit3 = results['hit_rate_3'] \n",
        "    f1 = results['f1_score']\n",
        "    improvement = ((hit1 - baseline_hit1) / baseline_hit1 * 100) if baseline_hit1 > 0 else 0\n",
        "    \n",
        "    print(f\"{method:<20} {hit1:<10.3f} {hit3:<10.3f} {f1:<10.3f} {improvement:<10.1f}%\")\n",
        "\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# 최종 시각화\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# 성능 지표별 서브플롯\n",
        "methods = list(all_results.keys())\n",
        "hit1_scores = [all_results[m]['hit_rate_1'] for m in methods]\n",
        "hit3_scores = [all_results[m]['hit_rate_3'] for m in methods]\n",
        "f1_scores = [all_results[m]['f1_score'] for m in methods]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Hit Rate @1\n",
        "axes[0,0].bar(methods, hit1_scores, color='skyblue', alpha=0.8)\n",
        "axes[0,0].set_title('Hit Rate @1 비교', fontsize=14, fontweight='bold')\n",
        "axes[0,0].set_ylabel('정확도')\n",
        "axes[0,0].tick_params(axis='x', rotation=45)\n",
        "axes[0,0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Hit Rate @3\n",
        "axes[0,1].bar(methods, hit3_scores, color='lightcoral', alpha=0.8)\n",
        "axes[0,1].set_title('Hit Rate @3 비교', fontsize=14, fontweight='bold')\n",
        "axes[0,1].set_ylabel('정확도')\n",
        "axes[0,1].tick_params(axis='x', rotation=45)\n",
        "axes[0,1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# F1 Score\n",
        "axes[1,0].bar(methods, f1_scores, color='lightgreen', alpha=0.8)\n",
        "axes[1,0].set_title('F1 Score 비교', fontsize=14, fontweight='bold')\n",
        "axes[1,0].set_ylabel('F1 Score')\n",
        "axes[1,0].tick_params(axis='x', rotation=45)\n",
        "axes[1,0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 종합 성능 (Hit@1 기준)\n",
        "improvements = [((score - baseline_hit1) / baseline_hit1 * 100) if baseline_hit1 > 0 else 0 for score in hit1_scores]\n",
        "colors = ['red' if imp < 0 else 'green' for imp in improvements]\n",
        "axes[1,1].bar(methods, improvements, color=colors, alpha=0.7)\n",
        "axes[1,1].set_title('V1 대비 향상도 (%)', fontsize=14, fontweight='bold')\n",
        "axes[1,1].set_ylabel('향상도 (%)')\n",
        "axes[1,1].tick_params(axis='x', rotation=45)\n",
        "axes[1,1].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
        "axes[1,1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('한국어 텍스트 분류 성능 종합 비교', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 🔍 결론 및 인사이트\n",
        "\n",
        "### 🎯 주요 발견사항\n",
        "\n",
        "1. **앙상블 기법의 효과**\n",
        "   - 단일 모델보다 앙상블이 일반적으로 더 안정적인 성능을 보임\n",
        "   - 가중치 조합이 성능에 중요한 영향을 미침\n",
        "\n",
        "2. **NER 전처리의 영향**\n",
        "   - 개체명 인식을 통한 텍스트 일반화가 성능 향상에 기여\n",
        "   - 특히 인물명, 장소명이 포함된 텍스트에서 효과적\n",
        "\n",
        "3. **키워드 기반 임베딩**\n",
        "   - 단순 카테고리명보다 행동 지향적 키워드가 더 효과적\n",
        "   - 도메인 특화 키워드 설계의 중요성\n",
        "\n",
        "4. **파인튜닝 효과**\n",
        "   - 작은 데이터셋에서도 파인튜닝이 성능 개선에 도움\n",
        "   - 앙상블과 결합 시 상승효과 기대\n",
        "\n",
        "### 💡 실무 적용 권장사항\n",
        "\n",
        "1. **단계적 접근**: V1 → V2 → V3 → V4 순으로 점진적 개선\n",
        "2. **데이터 품질**: 고품질 라벨링과 키워드 설계가 핵심\n",
        "3. **하이퍼파라미터**: 도메인별 최적 가중치 탐색 필요\n",
        "4. **리소스 고려**: 성능 대비 계산 비용 트레이드오프 검토\n",
        "\n",
        "### 🚀 향후 개선 방향\n",
        "\n",
        "- 더 다양한 앙상블 전략 (stacking, voting 등)\n",
        "- 대용량 데이터셋에서의 성능 검증\n",
        "- 실시간 추론 최적화\n",
        "- 도메인 적응 기법 적용\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎓 파인튜닝 클래스 정의\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers.evaluation import SentenceEvaluator\n",
        "import csv\n",
        "\n",
        "class QuickFinetuner:\n",
        "    \"\"\"빠른 파인튜닝을 위한 클래스 (Colab 최적화)\"\"\"\n",
        "    \n",
        "    def __init__(self, data_path, sample_size=50):\n",
        "        self.data_path = data_path\n",
        "        self.sample_size = sample_size\n",
        "        self.categories_definitions = CATEGORIES_DEFINITIONS\n",
        "        \n",
        "        # 데이터 준비\n",
        "        self.train_df, self.test_df = self._prepare_data()\n",
        "        \n",
        "    def _prepare_data(self):\n",
        "        \"\"\"파인튜닝용 데이터 준비\"\"\"\n",
        "        df = pd.read_csv(self.data_path)\n",
        "        \n",
        "        # 카테고리 컬럼 정규화\n",
        "        if 'categories' not in df.columns and 'category' in df.columns:\n",
        "            df = df.rename(columns={'category': 'categories'})\n",
        "        \n",
        "        df.dropna(subset=['title', 'categories'], inplace=True)\n",
        "        df['category'] = df['categories'].apply(lambda x: x.split(';')[0].strip() if isinstance(x, str) else x)\n",
        "        df = df[df['category'].isin(list(CATEGORIES_DEFINITIONS.keys()))]\n",
        "        \n",
        "        # 빠른 실행을 위해 작은 샘플 사용\n",
        "        if len(df) > self.sample_size:\n",
        "            df = df.sample(n=self.sample_size, random_state=42)\n",
        "        \n",
        "        # 훈련/테스트 분할\n",
        "        train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "        \n",
        "        # NER 전처리\n",
        "        train_df = train_df.copy()\n",
        "        test_df = test_df.copy()\n",
        "        train_df['generalized_title'] = ner_generalize_texts(train_df['title'].tolist())\n",
        "        test_df['generalized_title'] = ner_generalize_texts(test_df['title'].tolist())\n",
        "        \n",
        "        print(f\"✅ 파인튜닝 데이터 준비: 훈련 {len(train_df)}개, 테스트 {len(test_df)}개\")\n",
        "        return train_df, test_df\n",
        "    \n",
        "    def create_training_examples(self):\n",
        "        \"\"\"파인튜닝용 InputExample 생성\"\"\"\n",
        "        examples = []\n",
        "        for _, row in self.train_df.iterrows():\n",
        "            title = row['generalized_title']\n",
        "            category = row['category']\n",
        "            \n",
        "            # 해당 카테고리의 키워드들과 positive example 생성\n",
        "            if category in self.categories_definitions:\n",
        "                for keyword in self.categories_definitions[category]:\n",
        "                    examples.append(InputExample(texts=[title, keyword]))\n",
        "        \n",
        "        print(f\"✅ 파인튜닝 예시 생성: {len(examples)}개\")\n",
        "        return examples\n",
        "    \n",
        "    def quick_finetune(self, epochs=1):\n",
        "        \"\"\"빠른 파인튜닝 수행\"\"\"\n",
        "        print(\"🔄 파인튜닝 시작...\")\n",
        "        \n",
        "        # 모델 로드\n",
        "        model = SentenceTransformer(BASE_MODEL_NAME, device=device)\n",
        "        \n",
        "        # 훈련 예시 생성\n",
        "        train_examples = self.create_training_examples()\n",
        "        \n",
        "        # 데이터로더 생성\n",
        "        train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=8)\n",
        "        \n",
        "        # 손실 함수\n",
        "        train_loss = losses.MultipleNegativesRankingLoss(model)\n",
        "        \n",
        "        # 훈련 실행\n",
        "        model.fit(\n",
        "            train_objectives=[(train_dataloader, train_loss)],\n",
        "            epochs=epochs,\n",
        "            warmup_steps=int(len(train_dataloader) * 0.1),\n",
        "            show_progress_bar=True\n",
        "        )\n",
        "        \n",
        "        print(\"✅ 파인튜닝 완료\")\n",
        "        return model\n",
        "\n",
        "print(\"✅ 파인튜닝 클래스 정의 완료\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
